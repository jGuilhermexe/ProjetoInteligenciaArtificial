import os 
import pandas as pd  # Importa√ß√£o da biblioteca pandas para que seja poss√≠vel a leitura e manipula√ß√£o de tabelas (DataFrame)
import numpy as np  # Importa√ß√£o da biblioteca numpy para opera√ß√µes num√©ricas b√°sicas

# Ferramentas de valida√ß√£o e busca de par√¢metros do scikit-learn
from sklearn.model_selection import StratifiedKFold 
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Importando os 5 classificadores: √Årvore de Decis√£o, KNN, Naive Bayes, Regress√£o Log√≠stica e MLP
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1) CARREGAMENTO DO DATASET ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# L√™ o arquivo CSV fornecido pelo site do dataset para um DataFrame do pandas.
df = pd.read_csv("detect_dataset.csv")


# Fun√ß√£o para remover colunas vazias que vem diretamente do arquivo csv
# Se essas colunas n√£o existirem, o drop causar√° um erro ‚Äî use df.columns para checar.
df = df.drop(columns=["Unnamed: 7", "Unnamed: 8"])

# Fazendo a separa√ß√£o dos atributos (X) e r√≥tulos (y):
# - X deve contem apenas as features (dados de entrada num√©ricos)
# - y √© a coluna que cont√©m as classes que queremos prever

X = df.drop(columns=["Output (S)"])  # todas as colunas exceto a coluna de sa√≠da
y = df["Output (S)"]  # coluna principal

# Notifica√ß√µes importantes no terminal pra verificar que o dataset carregou corretamente:
print("Dataset carregado com sucesso!")
print("Primeiras linhas do DataFrame:")
print(df.head(), "\n")
print("Formato do DataFrame (linhas, colunas):", df.shape)


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 2) DEFINI√á√ÉO DOS MODELOS E PAR√ÇMETROS (m√≠nimo 3 combina√ß√µes) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Nesta vers√£o, **n√£o teremos par√¢metro nenhum**, pois isso ser√° feito pelo seu amigo.
# Mantemos APENAS os classificadores, como parte de "Uso dos Algoritmos".

modelos = {
    "Decision Tree": DecisionTreeClassifier(),  # √Årvore de Decis√£o
    "KNN": KNeighborsClassifier(),              # KNN
    "Naive Bayes": GaussianNB(),                # Naive Bayes
    "Regress√£o Log√≠stica": LogisticRegression(max_iter=500),  # Regress√£o Log√≠stica
    "MLP": MLPClassifier(max_iter=1000)         # MLP
}


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 3) FUN√á√ÉO DE AVALIA√á√ÉO EM 10-FOLD CV ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
def avaliar_modelo(nome, modelo, X, y):
    # Avalia um modelo usando Stratified 10-fold CV.
    #Calcula m√©tricas fold-a-fold pra obter m√©dia e desvio padr√£o com sucesso

    # Par√¢metros:
    # - nome: string com o nome do modelo (apenas para impress√£o)
    # - modelo: objeto classificador do sklearn (Como por exexmplo: DecisionTreeClassifier())
    # - X, y: dados e r√≥tulos (Biblioteca pandas e DataFrame / Series)


    print(f"\nüîµ Avaliando: {nome}")

    # Pipeline que aplica StandardScaler (normaliza√ß√£o) e depois o classificador.
    # A ordem √© importante: primeiro transforma√ß√µes (scaler), depois o estimador (clf).
    pipeline = Pipeline([
        ("scaler", StandardScaler()),  # step 'scaler'
        ("clf", modelo)                # step 'clf' que cont√©m o classificador
    ])

    # Cria√ß√£o do validador estratificado: garante que tenha a mesma propor√ß√£o de classes em cada fold.
    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

    # Listas para armazenar m√©tricas obtidas fold a fold.
    accs = []
    precs = []
    recalls = []
    f1s = []

    # Aqui iteramos explicitamente sobre os folds para calcular as m√©tricas manualmente.
    for train_idx, test_idx in cv.split(X, y):

        # Divis√£o manual entre treino e teste usando os √≠ndices do fold
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        # Treinando o pipeline completo neste fold
        pipeline.fit(X_train, y_train)

        # Prevendo apenas nas amostras do fold de teste
        preds = pipeline.predict(X_test)

        # Calculando m√©tricas para este fold e armazenar
        accs.append(accuracy_score(y_test, preds))
        precs.append(precision_score(y_test, preds))
        recalls.append(recall_score(y_test, preds))
        f1s.append(f1_score(y_test, preds))

    # Impress√£o dos resultados consolidados: m√©dias e desvios
    print(f"Acur√°cia: m√©dia={np.mean(accs):.4f} | desvio={np.std(accs):.4f}")
    print(f"Precis√£o: m√©dia={np.mean(precs):.4f} | desvio={np.std(precs):.4f}")
    print(f"Recall:   m√©dia={np.mean(recalls):.4f} | desvio={np.std(recalls):.4f}")
    print(f"F1-Score: m√©dia={np.mean(f1s):.4f} | desvio={np.std(f1s):.4f}")


#  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  4) EXECUTAR OS 5 MODELOS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Fun√ß√£o para executar os 5 modelos:
for nome, modelo in modelos.items():
    avaliar_modelo(nome, modelo, X, y)

#  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  PR√â-PROCESSAMENTO ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


import pandas as pd

print("\n INICIANDO PR√â-PROCESSAMENTO \n")

#Carregar dataset
df = pd.read_csv("classData.csv")

print("Shape original:", df.shape)
print("\nPrimeiros 5 registros:")
print(df.head())

#Informa√ß√µes b√°sicas sobre o dataset
print("\nTipos das colunas:")
print(df.dtypes)

print("\nValores ausentes por coluna:")
print(df.isnull().sum())

print("\nTotal de linhas duplicadas:", df.duplicated().sum())

#Limpeza para remover duplicadas e nulos
df_clean = df.drop_duplicates()
df_clean = df_clean.dropna()

print("\nShape ap√≥s remover duplicadas:", df_clean.shape)
print("Shape ap√≥s remover nulos:", df_clean.shape)

# Distribui√ß√£o da classe (detectada automaticamente)
coluna_classe = df.columns[-1]
print(f"\nDistribui√ß√£o da classe ({coluna_classe}):")
print(df[coluna_classe].value_counts())

#Salvar bases
df.to_csv("classData_original.csv", index=False)
df_clean.to_csv("classData_processada.csv", index=False)

print("\n Base original limpa salva como classData_original.csv")
print("\n Base processada salva como classData_processada.csv")
print("\n PR√â-PROCESSAMENTO CONCLU√çDO \n")



