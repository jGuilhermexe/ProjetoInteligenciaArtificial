import os 
import pandas as pd  # Importa√ß√£o da biblioteca pandas para que seja poss√≠vel a leitura e manipula√ß√£o de tabelas (DataFrame)
import numpy as np  # Importa√ß√£o da biblioteca numpy para opera√ß√µes num√©ricas b√°sicas

# Ferramentas de valida√ß√£o e busca de par√¢metros do scikit-learn
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Importando os 5 classificadores: √Årvore de Decis√£o, KNN, Naive Bayes, Regress√£o Log√≠stica e MLP
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier

#  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1) PR√â-PROCESSAMENTO ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

print("\n  Iniciando o pr√©-processamento do detect_dataset.csv \n")

#Carregar dataset
df_detect = pd.read_csv("detect_dataset.csv")

# Remove colunas vazias
# O par√¢metro 'errors='ignore'' evita erro caso as colunas "Unnamed: 7" e "Unnamed: 8" j√° tenham sido removidas ou n√£o existam.
df_detect = df_detect.drop(columns=["Unnamed: 7", "Unnamed: 8"], errors='ignore')

# In√≠cio da Impress√£o de Informa√ß√µes
print("Shape do DataFrame ap√≥s carregar e remover colunas vazias:", df_detect.shape)
print("\nPrimeiras 5 registros (com colunas vazias removidas):")
print(df_detect.head())

# Informa√ß√µes b√°sicas sobre o dataset
print("\nTipos das colunas:")
print(df_detect.dtypes)
print("\nValores ausentes por coluna (antes da limpeza):")
print(df_detect.isnull().sum())
print("\nTotal de linhas duplicadas (antes da limpeza):", df_detect.duplicated().sum())

# Limpeza para remover duplicadas e nulos
df_clean = df_detect.drop_duplicates()
df_clean = df_clean.dropna()
print("\nShape ap√≥s remover duplicadas:", df_clean.shape)
print("Shape ap√≥s remover nulos:", df_clean.shape)

# Distribui√ß√£o da classe (detectada automaticamente)
coluna_classe = df_detect.columns[0] 
print(f"\nDistribui√ß√£o da classe ({coluna_classe}):")
print(df_detect[coluna_classe].value_counts())

# Salvar bases
df_detect.to_csv("detect_dataset_original.csv", index=False)
df_clean.to_csv("detect_dataset_processada.csv", index=False)
print(f"\n Base original salva como detect_dataset_original.csv")
print(f"\n Base processada salva como detect_dataset_processada.csv")
print("\n PR√â-PROCESSAMENTO CONCLU√çDO \n")

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 2) CARREGAMENTO DO DATASET ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
print("Iniciando carregamento do dataset processado...")

# Carregando o dataset j√° processado.
df = pd.read_csv("detect_dataset_processada.csv")

# Fazendo a separa√ß√£o dos atributos (X) e r√≥tulos (y):
# - X deve contem apenas as features (dados de entrada num√©ricos)
# - y √© a coluna que cont√©m as classes que queremos prever
X = df.drop(columns=["Output (S)"])  # todas as colunas exceto a coluna de sa√≠da
y = df["Output (S)"]  # coluna principal

# Notifica√ß√µes importantes no terminal pra verificar que o dataset carregou corretamente:
print("Dataset processado carregado com sucesso!")
print("Primeiras linhas do DataFrame:")
print(df.head(), "\n")
print("Formato do DataFrame (linhas, colunas):", df.shape)


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 3) DEFINI√á√ÉO DOS MODELOS E PAR√ÇMETROS (m√≠nimo 3 combina√ß√µes) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Nesta vers√£o, **n√£o teremos par√¢metro nenhum**, pois isso ser√° feito pelo seu amigo.
# Mantemos APENAS os classificadores, como parte de "Uso dos Algoritmos".

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 3) DEFINI√á√ÉO DOS MODELOS E PAR√ÇMETROS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 3.1) Defini√ß√£o dos classificadores base (adicionado random_state para reprodutibilidade)
modelos = {
    "Decision Tree": DecisionTreeClassifier(random_state=42), 
    "KNN": KNeighborsClassifier(), 
    "Naive Bayes": GaussianNB(),
    "Regress√£o Log√≠stica": LogisticRegression(max_iter=500, random_state=42), 
    "MLP": MLPClassifier(max_iter=1000, random_state=42)
}

# 3.2) Defini√ß√£o dos grids de par√¢metros para OTIMIZA√á√ÉO (Crit√©rio 1.2)

# Grid para KNN (m√≠nimo de 3 combina√ß√µes garantido)
params_knn = {
    'clf__n_neighbors': [3, 5, 7, 9],  # K de 3, 5, 7 e 9
    'clf__weights': ['uniform', 'distance'] # Dois tipos de pesos
}

# Grid para Decision Tree (m√≠nimo de 3 combina√ß√µes garantido)
params_dt = {
    'clf__criterion': ['gini', 'entropy'], # Crit√©rios
    'clf__max_depth': [5, 10, None],      # Profundidade (5, 10 ou ilimitada)
    'clf__min_samples_split': [2, 10]     # M√≠nimo de amostras para um split
}

# Grid para MLP (m√≠nimo de 3 combina√ß√µes garantido)
params_mlp = {
    'clf__hidden_layer_sizes': [(50,), (100, 50)], # Estrutura das camadas ocultas
    'clf__activation': ['relu', 'tanh'],           # Fun√ß√µes de ativa√ß√£o
    'clf__alpha': [0.0001, 0.01]                   # Regulariza√ß√£o L2
}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 4) FUN√á√ÉO DE AVALIA√á√ÉO EM 10-FOLD CV ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
def avaliar_modelo(nome, modelo, X, y):
    # Avalia um modelo usando Stratified 10-fold CV.
    #Calcula m√©tricas fold-a-fold pra obter m√©dia e desvio padr√£o com sucesso
    # Par√¢metros:
    # - nome: string com o nome do modelo (apenas para impress√£o)
    # - modelo: objeto classificador do sklearn (Como por exexmplo: DecisionTreeClassifier())
    # - X, y: dados e r√≥tulos (Biblioteca pandas e DataFrame / Series)

    print(f"\n Avaliando: {nome}")

    # Pipeline que aplica StandardScaler (normaliza√ß√£o) e depois o classificador.
    # A ordem √© importante: primeiro transforma√ß√µes (scaler), depois o estimador (clf).
    pipeline = Pipeline([
        ("scaler", StandardScaler()),  # step 'scaler'
        ("clf", modelo)                # step 'clf' que cont√©m o classificador
    ])

    # Cria√ß√£o do validador estratificado: garante que tenha a mesma propor√ß√£o de classes em cada fold.
    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

    # Listas para armazenar m√©tricas obtidas fold a fold.
    accs = []
    precs = []
    recalls = []
    f1s = []

    # Aqui iteramos explicitamente sobre os folds para calcular as m√©tricas manualmente.
    for train_idx, test_idx in cv.split(X, y):

        # Divis√£o manual entre treino e teste usando os √≠ndices do fold
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        # Treinando o pipeline completo neste fold
        pipeline.fit(X_train, y_train)

        # Prevendo apenas nas amostras do fold de teste
        preds = pipeline.predict(X_test)

        # Calculando m√©tricas para este fold e armazenar
        accs.append(accuracy_score(y_test, preds))
        precs.append(precision_score(y_test, preds))
        recalls.append(recall_score(y_test, preds))
        f1s.append(f1_score(y_test, preds))

    # Impress√£o dos resultados consolidados: m√©dias e desvios
    print(f"Acur√°cia: m√©dia={np.mean(accs):.4f} | desvio={np.std(accs):.4f}")
    print(f"Precis√£o: m√©dia={np.mean(precs):.4f} | desvio={np.std(precs):.4f}")
    print(f"Recall:   m√©dia={np.mean(recalls):.4f} | desvio={np.std(recalls):.4f}")
    print(f"F1-Score: m√©dia={np.mean(f1s):.4f} | desvio={np.std(f1s):.4f}")


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 5) OTIMIZA√á√ÉO DE PAR√ÇMETROS (GridSearch) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

def otimizar_modelo(nome, modelo, parametros, X, y):
    print(f"\n‚ú® Otimizando Hiperpar√¢metros para: {nome} (GridSearch)")
    
    # Cria o Pipeline
    pipeline = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", modelo) 
    ])
    
    # Configura o GridSearchCV (usa 10-Fold CV interno)
    grid_search = GridSearchCV(
        estimator=pipeline, 
        param_grid=parametros, 
        scoring='f1_weighted', # Usamos F1-Score Ponderado como a m√©trica principal para o GridSearch
        cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42), 
        verbose=1, 
        n_jobs=-1 # Usa todos os n√∫cleos do processador para acelerar
    )
    
    # Executa o Grid Search
    grid_search.fit(X, y)
    
    # Imprime os resultados
    print(f"   üèÜ Melhor F1-Score (m√©dia CV): {grid_search.best_score_:.4f}")
    print(f"   ‚öôÔ∏è  Melhores Par√¢metros: {grid_search.best_params_}")
    
    # Retorna o melhor modelo encontrado
    return grid_search.best_estimator_['clf']


# --- Execu√ß√£o da Otimiza√ß√£o ---
melhores_modelos_otimizados = {}
print("\n" + "="*50)
print("INICIANDO A OTIMIZA√á√ÉO DE PAR√ÇMETROS (Crit√©rio 1.2)")
print("="*50)

# 1. Otimiza√ß√£o para KNN
melhores_modelos_otimizados["KNN (Otimizado)"] = otimizar_modelo(
    "KNN", KNeighborsClassifier(), params_knn, X, y
)

# 2. Otimiza√ß√£o para Decision Tree
melhores_modelos_otimizados["Decision Tree (Otimizada)"] = otimizar_modelo(
    "Decision Tree", DecisionTreeClassifier(random_state=42), params_dt, X, y
)

# 3. Otimiza√ß√£o para MLP
melhores_modelos_otimizados["MLP (Otimizado)"] = otimizar_modelo(
    "MLP", MLPClassifier(max_iter=1000, random_state=42), params_mlp, X, y
)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 6) EXECUTAR TODOS OS MODELOS (Originais e Otimizados) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Incluir os modelos otimizados na lista de modelos a serem avaliados
modelos.update(melhores_modelos_otimizados) 

print("\n" + "="*50)
print("AVALIA√á√ÉO FINAL (Originais e Otimizados)")
print("="*50)

# Avaliar todos os modelos (originais + otimizados)
for nome, modelo in modelos.items():
    avaliar_modelo(nome, modelo, X, y)