import os 
import pandas as pd  # Importa√ß√£o da biblioteca pandas para que seja poss√≠vel a leitura e manipula√ß√£o de tabelas (DataFrame)
import numpy as np  # Importa√ß√£o da biblioteca numpy para opera√ß√µes num√©ricas b√°sicas

# Ferramentas de valida√ß√£o e busca de par√¢metros do scikit-learn
from sklearn.model_selection import StratifiedKFold 
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Importando os 5 classificadores: √Årvore de Decis√£o, KNN, Naive Bayes, Regress√£o Log√≠stica e MLP
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier

#  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1) PR√â-PROCESSAMENTO ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

print("\n  Iniciando o pr√©-processamento do detect_dataset.csv \n")

#Carregar dataset
df_detect = pd.read_csv("detect_dataset.csv")

# Remove colunas vazias
# O par√¢metro 'errors='ignore'' evita erro caso as colunas "Unnamed: 7" e "Unnamed: 8" j√° tenham sido removidas ou n√£o existam.
df_detect = df_detect.drop(columns=["Unnamed: 7", "Unnamed: 8"], errors='ignore')

# In√≠cio da Impress√£o de Informa√ß√µes
print("Shape do DataFrame ap√≥s carregar e remover colunas vazias:", df_detect.shape)
print("\nPrimeiras 5 registros (com colunas vazias removidas):")
print(df_detect.head())

# Informa√ß√µes b√°sicas sobre o dataset
print("\nTipos das colunas:")
print(df_detect.dtypes)
print("\nValores ausentes por coluna (antes da limpeza):")
print(df_detect.isnull().sum())
print("\nTotal de linhas duplicadas (antes da limpeza):", df_detect.duplicated().sum())

# Limpeza para remover duplicadas e nulos
df_clean = df_detect.drop_duplicates()
df_clean = df_clean.dropna()
print("\nShape ap√≥s remover duplicadas:", df_clean.shape)
print("Shape ap√≥s remover nulos:", df_clean.shape)

# Distribui√ß√£o da classe (detectada automaticamente)
coluna_classe = df_detect.columns[0] 
print(f"\nDistribui√ß√£o da classe ({coluna_classe}):")
print(df_detect[coluna_classe].value_counts())

# Salvar bases
df_detect.to_csv("detect_dataset_original.csv", index=False)
df_clean.to_csv("detect_dataset_processada.csv", index=False)
print(f"\n Base original salva como detect_dataset_original.csv")
print(f"\n Base processada salva como detect_dataset_processada.csv")
print("\n PR√â-PROCESSAMENTO CONCLU√çDO \n")

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 2) CARREGAMENTO DO DATASET ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
print("Iniciando carregamento do dataset processado...")

# üî¥ CORRE√á√ÉO: L√™ o arquivo CSV FINAL (limpo de nulos, duplicatas e colunas vazias)
df = pd.read_csv("detect_dataset_processada.csv")

# Fazendo a separa√ß√£o dos atributos (X) e r√≥tulos (y):
# - X deve contem apenas as features (dados de entrada num√©ricos)
# - y √© a coluna que cont√©m as classes que queremos prever
X = df.drop(columns=["Output (S)"])  # todas as colunas exceto a coluna de sa√≠da
y = df["Output (S)"]  # coluna principal

# Notifica√ß√µes importantes no terminal pra verificar que o dataset carregou corretamente:
print("Dataset processado carregado com sucesso!")
print("Primeiras linhas do DataFrame:")
print(df.head(), "\n")
print("Formato do DataFrame (linhas, colunas):", df.shape)


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 3) DEFINI√á√ÉO DOS MODELOS E PAR√ÇMETROS (m√≠nimo 3 combina√ß√µes) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Nesta vers√£o, **n√£o teremos par√¢metro nenhum**, pois isso ser√° feito pelo seu amigo.
# Mantemos APENAS os classificadores, como parte de "Uso dos Algoritmos".

modelos = {
    "Decision Tree": DecisionTreeClassifier(),  # √Årvore de Decis√£o
    "KNN": KNeighborsClassifier(),              # KNN
    "Naive Bayes": GaussianNB(),                # Naive Bayes
    "Regress√£o Log√≠stica": LogisticRegression(max_iter=500),  # Regress√£o Log√≠stica
    "MLP": MLPClassifier(max_iter=1000)         # MLP
}


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 4) FUN√á√ÉO DE AVALIA√á√ÉO EM 10-FOLD CV ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
def avaliar_modelo(nome, modelo, X, y):
    # Avalia um modelo usando Stratified 10-fold CV.
    #Calcula m√©tricas fold-a-fold pra obter m√©dia e desvio padr√£o com sucesso

    # Par√¢metros:
    # - nome: string com o nome do modelo (apenas para impress√£o)
    # - modelo: objeto classificador do sklearn (Como por exexmplo: DecisionTreeClassifier())
    # - X, y: dados e r√≥tulos (Biblioteca pandas e DataFrame / Series)


    print(f"\nüîµ Avaliando: {nome}")

    # Pipeline que aplica StandardScaler (normaliza√ß√£o) e depois o classificador.
    # A ordem √© importante: primeiro transforma√ß√µes (scaler), depois o estimador (clf).
    pipeline = Pipeline([
        ("scaler", StandardScaler()),  # step 'scaler'
        ("clf", modelo)                # step 'clf' que cont√©m o classificador
    ])

    # Cria√ß√£o do validador estratificado: garante que tenha a mesma propor√ß√£o de classes em cada fold.
    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

    # Listas para armazenar m√©tricas obtidas fold a fold.
    accs = []
    precs = []
    recalls = []
    f1s = []

    # Aqui iteramos explicitamente sobre os folds para calcular as m√©tricas manualmente.
    for train_idx, test_idx in cv.split(X, y):

        # Divis√£o manual entre treino e teste usando os √≠ndices do fold
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        # Treinando o pipeline completo neste fold
        pipeline.fit(X_train, y_train)

        # Prevendo apenas nas amostras do fold de teste
        preds = pipeline.predict(X_test)

        # Calculando m√©tricas para este fold e armazenar
        accs.append(accuracy_score(y_test, preds))
        precs.append(precision_score(y_test, preds))
        recalls.append(recall_score(y_test, preds))
        f1s.append(f1_score(y_test, preds))

    # Impress√£o dos resultados consolidados: m√©dias e desvios
    print(f"Acur√°cia: m√©dia={np.mean(accs):.4f} | desvio={np.std(accs):.4f}")
    print(f"Precis√£o: m√©dia={np.mean(precs):.4f} | desvio={np.std(precs):.4f}")
    print(f"Recall:   m√©dia={np.mean(recalls):.4f} | desvio={np.std(recalls):.4f}")
    print(f"F1-Score: m√©dia={np.mean(f1s):.4f} | desvio={np.std(f1s):.4f}")


#  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  5) EXECUTAR OS 5 MODELOS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Fun√ß√£o para executar os 5 modelos:
for nome, modelo in modelos.items():
    avaliar_modelo(nome, modelo, X, y)
